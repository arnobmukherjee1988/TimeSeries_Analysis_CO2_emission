# Import reqired libraries
import numpy as np
import yfinance as yf
import pandas as pd
import seaborn as sns
import matplotlib as mpl
import matplotlib.dates as mdates
from datetime import datetime
from scipy.stats import norm
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_absolute_error, mean_squared_error
import os
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from scipy.stats import gaussian_kde
from matplotlib.backends.backend_pdf import PdfPages
from mpl_toolkits.axes_grid1.inset_locator import inset_axes
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.tsa.stattools import acf as sm_acf, pacf as sm_pacf
import pmdarima as pm
import warnings
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Suppress warnings for cleaner output
warnings.filterwarnings("ignore")

# Set display options
pd.set_option('display.max_columns', None)  # Display all columns
pd.set_option('display.width', 1000)        # Set display width to a high value


# Function to print colored text
def print_colored(text, color):
    color_codes = {
        'black': '0;30',
        'red': '0;31',
        'green': '0;32',
        'yellow': '0;33',
        'blue': '0;34',
        'purple': '0;35',
        'cyan': '0;36',
        'white': '0;37',
        'bold_black': '1;30',
        'bold_red': '1;31',
        'bold_green': '1;32',
        'bold_yellow': '1;33',
        'bold_blue': '1;34',
        'bold_purple': '1;35',
        'bold_cyan': '1;36',
        'bold_white': '1;37'
    }
    color_code = color_codes.get(color, '0;30')  # Default to white if color not found
    print(f"\033[{color_code}m{text}\033[0m")

nice_fonts = {
        # Use LaTeX to write all text
        "text.usetex": True,
        "font.family": "serif",
        # Use 10pt font in plots, to match 10pt font in document
        "axes.labelsize": 10,
        "font.size": 10,
        # Make the legend/label fonts a little smaller
        "legend.fontsize": 10,
        "xtick.labelsize": 10,
        "ytick.labelsize": 10,
        #'text.latex.preamble' : [r'\usepackage{amsmath}'],
        'mathtext.fontset' : 'stix',
        'mathtext.rm' : 'serif'
}
mpl.rcParams.update(nice_fonts)


# Reload the data, skipping the initial lines with header text
file_path = './ex3_1.dat'

# Reload the data from the file with correct column names
data = pd.read_csv(file_path, sep='\s+', comment='#', header=None, names=['Decimal Date', 'CO2 Concentration', 'Month'])

# Display the first few rows of the DataFrame to confirm the index change
data.head()


# Convert 'Decimal Date' to datetime format without time
data['Date'] = pd.to_datetime(data['Decimal Date'], format='%Y') + pd.to_timedelta((data['Decimal Date'] % 1) * 365, unit='D')

# Strip the time component from the 'Date'
data['Date'] = data['Date'].dt.to_period('M').dt.to_timestamp()

# Set 'Date' as the index
data.set_index('Date', inplace=True)

# Drop the 'Decimal Date' column as it's no longer needed
data.drop(columns=['Decimal Date'], inplace=True)

# Display the first few rows of the DataFrame to confirm the index change
data.head()


# Check for missing values
missing_values = data.isnull().sum()

# Check for duplicates
duplicates = data.duplicated().sum()

# Remove any duplicates if present
data_cleaned = data.drop_duplicates()

# Display the number of missing values and duplicates
missing_values, duplicates, data_cleaned.head()


# Check the frequency of the data
frequency_counts = data_cleaned.index.to_series().diff().value_counts()
frequency_counts



import matplotlib.pyplot as plt

# Plot the CO2 Concentration over time
plt.figure(figsize=(12, 6))
plt.plot(data_cleaned.index, data_cleaned['CO2 Concentration'], label='CO2 Concentration', color='blue')
plt.title('Monthly CO2 Concentration Over Time')
plt.xlabel('Year')
plt.ylabel(r'CO2 Concentration ($\mu$mol/mol)')
plt.legend()
plt.grid(True)
plt.show()



def trend_analysis(df, field):
    
    # Decompose the time series for trend analysis
    decomposition = seasonal_decompose(df[field], model='additive', period=12)
    trend = decomposition.trend
    seasonal = decomposition.seasonal
    residual = decomposition.resid

    # Create a large plot with subplots for various analyses
    fig, axes = plt.subplots(4, 1, figsize=(14, 10))
    
    # Time series of closing price
    axes[0].plot(df.index, df[field], label=field, color='blue')
    axes[0].set_ylabel('CO2 Concentration')
    axes[0].set_xlabel('Year')
    axes[0].legend(loc='best')
    axes[0].set_xlim(df.index.min(), df.index.max())
    axes[0].set_ylim(df[field].min(), df[field].max())
    
    # Trend analysis
    axes[1].plot(df.index, trend, label='Trend', color='orange')
    axes[1].set_xlabel('Year')
    axes[1].set_ylabel('CO2 Concentration')
    axes[1].legend(loc='best')
    axes[1].set_xlim(df.index.min(), df.index.max())
    axes[1].set_ylim(trend.min(), trend.max())
    
    # Trend analysis seasonal
    axes[2].plot(df.index, seasonal, label='Seasonal', color='green')
    axes[2].set_xlabel('Year')
    axes[2].set_ylabel('CO2 Concentration')
    axes[2].legend(loc='best')
    axes[2].set_xlim(df.index.min(), df.index.max())
    axes[2].set_ylim(seasonal.min(), seasonal.max())
    
    # Trend analysis residual
    axes[3].plot(df.index, residual, label='Residual', color='red')
    axes[3].set_xlabel('Year')
    axes[3].set_ylabel('CO2 Concentration')
    axes[3].legend(loc='best')
    axes[3].set_xlim(df.index.min(), df.index.max())
    axes[3].set_ylim(residual.min(), residual.max())
    

    # Save the figure to the PDF and show it
    plt.show()

trend_analysis(data_cleaned, 'CO2 Concentration')





# Calculate the rolling mean and standard deviation
window_size = 12  # Typically, a window size of 12 months is used for monthly data
rolling_mean = data_cleaned['CO2 Concentration'].rolling(window=window_size).mean()
rolling_std = data_cleaned['CO2 Concentration'].rolling(window=window_size).std()

# Plot the original data, rolling mean, and rolling standard deviation
plt.figure(figsize=(12, 6))
plt.plot(data_cleaned['CO2 Concentration'], label='Original', color='blue')
plt.plot(rolling_mean, label='Rolling Mean', color='orange')
plt.plot(rolling_std, label='Rolling Std Dev', color='green')
plt.title(r'Rolling Mean $\&$ Standard Deviation')
plt.xlabel('Year')
plt.ylabel(r'CO2 Concentration ($\mu$mol/mol)')
plt.legend()
plt.grid(True)
plt.show()









def adf_test(series, significance_level=0.05):
    """
    Perform the Augmented Dickey-Fuller test on a given time series.
    
    Parameters:
        series (pandas.Series): The time series data to test.
        significance_level (float): The significance level to use for the test (default is 0.05).
    
    Returns:
        dict: A dictionary containing the ADF statistic, p-value, and critical values.
    """
    # Perform the Augmented Dickey-Fuller test
    result = adfuller(series)
    
    # Extract results
    adf_statistic = result[0]
    p_value = result[1]
    critical_values = result[4]
    
    # Print the results
    print('ADF Statistic:', adf_statistic)
    print('p-value:', p_value)
    print('Critical Values:')
    for key, value in critical_values.items():
        print(f'   {key}: {value}')
    
    # Determine stationarity based on p-value and ADF statistic
    is_stationary = p_value < significance_level and adf_statistic < critical_values['5%']
    
    # Comparative analysis
    print('\nComparative Analysis:')
    if adf_statistic < critical_values['1%']:
        print(f"The ADF statistic {adf_statistic:.4f} is less than the 1% critical value {critical_values['1%']:.4f}.")
        print("The time series is strongly stationary at the 1% significance level.")
    elif adf_statistic < critical_values['5%']:
        print(f"The ADF statistic {adf_statistic:.4f} is less than the 5% critical value {critical_values['5%']:.4f}.")
        print("The time series is stationary at the 5% significance level.")
    elif adf_statistic < critical_values['10%']:
        print(f"The ADF statistic {adf_statistic:.4f} is less than the 10% critical value {critical_values['10%']:.4f}.")
        print("The time series is weakly stationary at the 10% significance level.")
    else:
        print(f"The ADF statistic {adf_statistic:.4f} is greater than all critical values.")
        print("The time series is non-stationary.")
    
    # Check p-value for stationarity
    if p_value < significance_level:
        print(f"\nThe p-value {p_value:.4f} is less than the significance level {significance_level}.")
        print("This provides strong evidence against the null hypothesis, suggesting the time series is stationary.")
    else:
        print(f"\nThe p-value {p_value:.4f} is greater than the significance level {significance_level}.")
        print("This suggests that the time series is non-stationary.")

    # Conclusion based on both tests
    if is_stationary:
        print("\nConclusion: The time series is stationary based on both ADF statistic and p-value.")
    else:
        print("\nConclusion: The time series is non-stationary based on either ADF statistic or p-value.")
    
    return {
        'ADF Statistic': adf_statistic,
        'p-value': p_value,
        'Critical Values': critical_values,
        'Stationary': is_stationary
    }


adf_test (data_cleaned['CO2 Concentration'])





def make_stationary(series):
    """
    Iteratively apply transformations to make a time series stationary.
    
    Parameters:
        series (pandas.Series): The non-stationary time series data.
    
    Returns:
        pandas.Series: The transformed stationary series.
    """
    # Perform first-order differencing
    diff1_series = series.diff().dropna()
    print("\nPerforming First-order Differencing:")
    adf_result_1 = adf_test(diff1_series)
    
    if adf_result_1['Stationary']:
        print("The series is stationary after first-order differencing.")
        plt.figure(figsize=(12, 6))
        plt.plot(diff1_series, label='First-order Differenced Series', color='purple')
        plt.title('First-order Differencing')
        plt.xlabel('Year')
        plt.ylabel('Differenced CO2 Concentration')
        plt.legend()
        plt.grid(True)
        plt.show()
        return diff1_series

    # Perform second-order differencing
    diff2_series = diff1_series.diff().dropna()
    print("\nPerforming Second-order Differencing:")
    adf_result_2 = adf_test(diff2_series)
    
    if adf_result_2['Stationary']:
        print("The series is stationary after second-order differencing.")
        plt.figure(figsize=(12, 6))
        plt.plot(diff2_series, label='Second-order Differenced Series', color='purple')
        plt.title('Second-order Differencing')
        plt.xlabel('Year')
        plt.ylabel('Differenced CO2 Concentration')
        plt.legend()
        plt.grid(True)
        plt.show()
        return diff2_series

    # Apply log transformation and first-order differencing
    log_series = np.log(series)
    log_diff_series = log_series.diff().dropna()
    print("\nApplying Log Transformation and First-order Differencing:")
    adf_result_log = adf_test(log_diff_series)
    
    if adf_result_log['Stationary']:
        print("The series is stationary after log transformation and first-order differencing.")
        plt.figure(figsize=(12, 6))
        plt.plot(log_diff_series, label='Log Differenced Series', color='purple')
        plt.title('Log Transformation and First-order Differencing')
        plt.xlabel('Year')
        plt.ylabel('Log Differenced CO2 Concentration')
        plt.legend()
        plt.grid(True)
        plt.show()
        return log_diff_series
    
    # Return the transformed series if stationary
    print("Unable to achieve stationarity with the applied transformations.")
    return log_diff_series


result_stationary = make_stationary(data_cleaned['CO2 Concentration'])


result_stationary


def acf_pacf_plot (series):
    # Plot ACF and PACF
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    plot_acf(series, ax=axes[0], lags=40)
    plot_pacf(series, ax=axes[1], lags=40)
    axes[0].set_title(f'ACF Plot')
    axes[1].set_title(f'PACF Plot')
    plt.show()


acf_pacf_plot (result_stationary) 


# Calculate ACF and PACF values and their significance bands for the first 10 lags
acf_values, acf_confint = acf(result_stationary, nlags=10, alpha=0.05)
pacf_values, pacf_confint = pacf(result_stationary, nlags=10, alpha=0.05)

# Extract the significance bands (confidence intervals)
acf_significance_upper = acf_confint[:, 1] - acf_values
acf_significance_lower = acf_values - acf_confint[:, 0]

pacf_significance_upper = pacf_confint[:, 1] - pacf_values
pacf_significance_lower = pacf_values - pacf_confint[:, 0]

# Create a DataFrame to display ACF and PACF values along with significance bands
acf_pacf_df = pd.DataFrame({
    'Lag': range(11),
    'ACF': acf_values,
    'ACF Upper': acf_significance_upper,
    'ACF Lower': acf_significance_lower,
    'PACF': pacf_values,
    'PACF Upper': pacf_significance_upper,
    'PACF Lower': pacf_significance_lower
})

acf_pacf_df





def my_acf(series, lags):
    """Calculate ACF manually."""
    n = len(series)
    gamma0 = np.dot(series, series) / n
    acf_manual = np.zeros(lags)

    for j in range(1, lags + 1):
        acf_manual[j - 1] = np.dot(series[:-j], series[j:])

    acf_manual /= n
    rho_manual = acf_manual / gamma0

    return rho_manual

def manual_pacf(series, lags):
    n = len(series)
    pacf_manual = np.zeros(lags)
    pacf_manual[0] = 1

    phi = np.zeros((lags, lags))
    phi[0, 0] = np.corrcoef(series[1:], series[:-1])[0, 1]  # First lag correlation

    pacf_manual[1] = phi[0, 0]

    for k in range(2, lags):
        # Autocorrelation calculations
        rho = my_acf(series, k + 1)

        # Compute phi[k, k]
        phi[k - 1, k - 1] = rho[k - 1]
        for j in range(1, k):
            phi[k - 1, k - 1] -= phi[j - 1, k - 2] * rho[k - j - 1]

        phi[k - 1, k - 1] /= (1 - sum(phi[j - 1, k - 2] ** 2 for j in range(1, k)))

        # Update phi[k, j] for j < k
        for j in range(1, k):
            phi[j - 1, k - 1] = phi[j - 1, k - 2] - phi[k - 1, k - 1] * phi[k - j - 1, k - 2]

        pacf_manual[k] = phi[k - 1, k - 1]

    return pacf_manual


def acf_pacf_comparison(series, lags=40):
    """Compare manually calculated ACF and PACF with statsmodels results."""
    
    # Calculate ACF and PACF manually
    acf_manual_values = my_acf(series, lags)
    pacf_manual_values = manual_pacf(series, lags)
    
    # Calculate ACF and PACF using statsmodels
    acf_statsmodels_values = sm_acf(series, nlags=lags, fft=True)
    pacf_statsmodels_values = sm_pacf(series, nlags=lags, method='ols')
    
    # Plot ACF comparison
    plt.figure(figsize=(14, 6))
    plt.subplot(1, 2, 1)
    plt.bar(np.arange(1, lags + 1) - 0.2, acf_manual_values[:lags], width=0.4, label='Manual ACF', color='skyblue')
    plt.bar(np.arange(1, lags + 1) + 0.2, acf_statsmodels_values[1:lags + 1], width=0.4, label='Statsmodels ACF', color='orange')
    plt.xlabel('Lag')
    plt.ylabel('ACF Value')
    plt.title('ACF Comparison')
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.axhline(y=0, color='black', linewidth=0.5)
    plt.xticks(np.arange(1, lags + 1, 2))
    plt.ylim(-1, 1)
    plt.legend()
    
    # Plot PACF comparison
    plt.subplot(1, 2, 2)
    plt.bar(np.arange(1, lags + 1) - 0.2, pacf_manual_values[:lags], width=0.4, label='Manual PACF', color='skyblue')
    plt.bar(np.arange(1, lags + 1) + 0.2, pacf_statsmodels_values[:lags], width=0.4, label='Statsmodels PACF', color='orange')
    plt.xlabel('Lag')
    plt.ylabel('PACF Value')
    plt.title('PACF Comparison')
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.axhline(y=0, color='black', linewidth=0.5)
    plt.xticks(np.arange(1, lags + 1, 2))
    plt.ylim(-1, 1)
    plt.legend()
    
    plt.tight_layout()
    plt.show()


acf_pacf_plot(result_stationary)
acf_pacf_comparison(result_stationary, lags=30)


# Determine the split index for 60% training and 40% testing
train_size = int(len(data_cleaned['CO2 Concentration']) * 0.6)

# Split the data into training and test sets
train_data = data_cleaned['CO2 Concentration'][:train_size]
test_data = data_cleaned['CO2 Concentration'][train_size:]

# Print the sizes of the datasets
print("Training Set Size:", len(train_data))
print("Test Set Size:", len(test_data))

# Visualize the split
plt.figure(figsize=(12, 6))
plt.plot(data_cleaned['CO2 Concentration'], label='Full Series', color='blue')
plt.axvline(x=train_data.index[-1], color='red', linestyle='--', label='Train-Test Split')
plt.title('Train-Test Split')
plt.xlabel('Year')
plt.ylabel('Differenced CO2 Concentration')
plt.legend()
plt.grid(True)
plt.show()



# Set the frequency of the time series data to monthly
train_data = train_data.asfreq('MS')
test_data = test_data.asfreq('MS')

# Build and fit the ARIMA model
model = ARIMA(train_data, order=(1, 2, 1))
fitted_model = model.fit()


# Print model summary
print(fitted_model.summary())

# Make predictions on the test set
predictions = fitted_model.forecast(steps=len(test_data))

# Evaluate model performance
mae = mean_absolute_error(test_data, predictions)
rmse = np.sqrt(mean_squared_error(test_data, predictions))

# Print performance metrics
print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Root Mean Square Error (RMSE): {rmse:.4f}")

# Plot actual vs. predicted values
plt.figure(figsize=(12, 6))
plt.plot(test_data.index, test_data, label='Actual', color='blue')
plt.plot(test_data.index, predictions, label='Predicted', color='orange')
plt.title('Actual vs. Predicted Values')
plt.xlabel('Year')
plt.ylabel('Differenced CO2 Concentration')
plt.legend()
plt.grid(True)
plt.show()


# Fit SARIMA model
# Assuming a seasonal period of 6 months
seasonal_order = (1, 1, 2, 6)

sarima_model = SARIMAX(train_data, order=(1, 2, 1), seasonal_order=seasonal_order)
sarima_fitted_model = sarima_model.fit()


# Make predictions on the test set
sarima_predictions = sarima_fitted_model.forecast(steps=len(test_data))

# Evaluate SARIMA model performance
sarima_mae = mean_absolute_error(test_data, sarima_predictions)
sarima_rmse = np.sqrt(mean_squared_error(test_data, sarima_predictions))

print(f"SARIMA Mean Absolute Error (MAE): {sarima_mae:.4f}")
print(f"SARIMA Root Mean Square Error (RMSE): {sarima_rmse:.4f}")

# Plot actual vs. predicted values
plt.figure(figsize=(12, 6))
plt.plot(test_data.index, test_data, label='Actual', color='blue')
plt.plot(test_data.index, sarima_predictions, label='SARIMA Predicted', color='orange')
plt.title('Actual vs. SARIMA Predicted Values')
plt.xlabel('Year')
plt.ylabel('Differenced CO2 Concentration')
plt.legend()
plt.grid(True)
plt.show()





from prophet import Prophet


# Load the data from the file with correct column names
file_path = 'ex3_1.dat'  # Update this path to your local file path
data = pd.read_csv(file_path, sep='\s+', comment='#', header=None, names=['Decimal Date', 'CO2 Concentration', 'Month'])

# Convert 'Decimal Date' to datetime format without time
data['Date'] = pd.to_datetime(data['Decimal Date'], format='%Y') + pd.to_timedelta((data['Decimal Date'] % 1) * 365, unit='D')

# Strip the time component from the 'Date'
data['Date'] = data['Date'].dt.to_period('M').dt.to_timestamp()

# Set 'Date' as the index
data.set_index('Date', inplace=True)

# Prepare the data for Prophet
prophet_data = data.reset_index().rename(columns={'Date': 'ds', 'CO2 Concentration': 'y'})

# Initialize Prophet model
prophet_model = Prophet(yearly_seasonality=True, daily_seasonality=False, weekly_seasonality=False)

# Fit the model
prophet_model.fit(prophet_data)


# Make future predictions
future = prophet_model.make_future_dataframe(periods=24, freq='M')  # 24 months into the future
forecast = prophet_model.predict(future)

# Plot the forecast
prophet_model.plot(forecast)
plt.title('Prophet Forecast')
plt.xlabel('Year')
plt.ylabel('CO2 Concentration')
plt.grid(True)
plt.show()

# Evaluate the Prophet model performance on historical data
actual = prophet_data['y']
predicted = forecast.set_index('ds').loc[prophet_data['ds'], 'yhat']

# Calculate error metrics for Prophet
prophet_mae = mean_absolute_error(actual, predicted)
prophet_rmse = np.sqrt(mean_squared_error(actual, predicted))

print(f"Prophet Mean Absolute Error (MAE): {prophet_mae:.4f}")
print(f"Prophet Root Mean Square Error (RMSE): {prophet_rmse:.4f}")


# Use auto_arima to determine the best ARIMA and SARIMA parameters
auto_model = pm.auto_arima(
    train_data,
    seasonal=True,
    m=12,  # Monthly data with annual seasonality
    trace=True,
    error_action='ignore',
    suppress_warnings=True,
    stepwise=True,
    n_jobs=-1
)


# Print the best model parameters
print(f"Best Model Order: {auto_model.order}")
print(f"Best Seasonal Order: {auto_model.seasonal_order}")

# Forecast the future values
predictions = auto_model.predict(n_periods=len(test_data))

# Ensure the predictions are in a compatible format
predictions = np.array(predictions).flatten()
test_values = test_data.values.flatten()

# Evaluate the model performance
auto_model_mae = mean_absolute_error(test_values, predictions)
auto_model_rmse = np.sqrt(mean_squared_error(test_values, predictions))

print(f"Mean Absolute Error (MAE): {auto_model_mae:.4f}")
print(f"Root Mean Square Error (RMSE): {auto_model_rmse:.4f}")

# Plot the actual vs. predicted values
plt.figure(figsize=(12, 6))
plt.plot(test_data.index, test_values, label='Actual', color='blue')
plt.plot(test_data.index, predictions, label='Predicted', color='red')
plt.plot(test_data.index, sarima_predictions, label='SARIMA Predicted', color='orange')
plt.title('Actual vs. Predicted Values (Auto ARIMA)')
plt.xlabel('Year')
plt.ylabel('CO2 Concentration')
plt.legend()
plt.grid(True)
plt.show()


# Forecast future values
n_future_months = 24  # Forecasting 24 months into the future
future_forecast = auto_model.predict(n_periods=n_future_months)

# Create a future date range
last_date = data.index[-1]
future_dates = pd.date_range(last_date + pd.DateOffset(months=1), periods=n_future_months, freq='M')

# Plot historical and forecasted data
plt.figure(figsize=(12, 6))
plt.plot(data.index, data['CO2 Concentration'], label='Historical Data', color='blue')
plt.plot(future_dates, future_forecast, label='Future Forecast', color='red')
plt.title('Future CO2 Concentration Forecast')
plt.xlabel('Year')
plt.ylabel('CO2 Concentration')
plt.legend()
plt.grid(True)
plt.show()

# Display forecasted values
forecast_df = pd.DataFrame({'Date': future_dates, 'Forecasted CO2': future_forecast})
forecast_df.set_index('Date', inplace=True)

forecast_df.head()


print(f"SARIMA Mean Absolute Error (MAE): {sarima_mae:.4f}")
print(f"SARIMA Root Mean Square Error (RMSE): {sarima_rmse:.4f}")

print(f"Mean Absolute Error (MAE): {auto_model_mae:.4f}")
print(f"Root Mean Square Error (RMSE): {auto_model_rmse:.4f}")

print(f"Prophet Mean Absolute Error (MAE): {prophet_mae:.4f}")
print(f"Prophet Root Mean Square Error (RMSE): {prophet_rmse:.4f}")

print(f"Mean Absolute Error (MAE): {mae:.4f}")
print(f"Root Mean Square Error (RMSE): {rmse:.4f}")


# Use auto_arima to determine the best ARIMA and SARIMA parameters
auto_model = pm.auto_arima(
    data_cleaned['CO2 Concentration'],
    seasonal=True,
    m=12,  # Monthly data with annual seasonality
    trace=True,
    error_action='ignore',
    suppress_warnings=True,
    stepwise=True,
    n_jobs=-1
)


# Forecast future values
n_future_months = 24  # Forecasting 24 months into the future
future_forecast = auto_model.predict(n_periods=n_future_months)

# Create a future date range
last_date = data.index[-1]
future_dates = pd.date_range(last_date + pd.DateOffset(months=1), periods=n_future_months, freq='M')

# Plot historical and forecasted data
plt.figure(figsize=(14, 7))
plt.plot(data.index, data['CO2 Concentration'], label='Historical Data', color='blue')
plt.plot(future_dates, future_forecast, label='Future Forecast', color='red', linestyle='--')
plt.title('Future CO2 Concentration Forecast')
plt.xlabel('Year')
plt.ylabel('CO2 Concentration')
plt.legend()
plt.grid(True)
plt.show()


# Forecast future values
n_future_months = 24  # Forecasting 24 months into the future
future_forecast = auto_model.predict(n_periods=n_future_months)

# Create a future date range
last_date = data.index[-1]
future_dates = pd.date_range(last_date + pd.DateOffset(months=1), periods=n_future_months, freq='M')

# Ensure future forecast has values
print(f"Future Forecast: {future_forecast}")

# Create a DataFrame for the forecasted data
forecast_df = pd.DataFrame(future_forecast, index=future_dates, columns=['Forecasted CO2'])

# Combine historical and forecast data for plotting
combined_data = pd.concat([data['CO2 Concentration'], forecast_df['Forecasted CO2']])

# Print combined data to verify
print(combined_data.tail(30))

# Plot historical and forecasted data
plt.figure(figsize=(14, 7))
plt.plot(combined_data.index, combined_data, label='Historical and Future Forecast', color='blue')
plt.axvline(x=last_date, color='red', linestyle='--', label='Forecast Start')
plt.title('Future CO2 Concentration Forecast')
plt.xlabel('Year')
plt.ylabel('CO2 Concentration')
plt.legend()
plt.grid(True)
plt.show()

























































